{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A2_Report.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7h2peFTqdbjw",
        "35u90OYYeoek",
        "uHL25pckhjTY",
        "w0N9lLcEh25_",
        "xbqHQVG_bQe8",
        "tlRU_DNUihn7",
        "2LKvkKeBrP4z",
        "Pt7TgvAaMtMg",
        "UBGoYYze_OUG"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tunrham/UTS_ML2019_ID11403868/blob/master/A2_Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXsJVegIXOtz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "########################## Student Number: 11403868 ############################\n",
        "########################### Subject Number: 31005  #############################\n",
        "################################################################################\n",
        "##################### Below is Model Code used creating a ######################\n",
        "################### LSTM Predicting Tennis Rally Sequences #####################\n",
        "################################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDsNu2f4omGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "############################## Assignment Links ################################\n",
        "################################################################################\n",
        "### Code: https://github.com/Tunrham/UTS_ML2019_ID11403868/blob/master/A2_Model_Code.ipynb\n",
        "### Youtube Link: "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHzxrOT_a3e1",
        "colab_type": "text"
      },
      "source": [
        "# Practical Machine Learning Project: Using LSTM for Pattern Recognition in Tennis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kehlzNyWbLM1",
        "colab_type": "text"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7h2peFTqdbjw",
        "colab_type": "text"
      },
      "source": [
        "### Introduction\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I30-V-O3s75I",
        "colab_type": "text"
      },
      "source": [
        "The role of analytics is historically documented in sports, from Bill James' Sabremetrics for Baseball in the 1980's, to analytics' role today in multi-billion dollar sports leagues including the National Basketball Association and the English Premier League. Tennis however, has always lagged behind - with data rarely publically available, and any data solutions occuring quietly, behind closed doors. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiy97xw57R_2",
        "colab_type": "text"
      },
      "source": [
        "In this Project, I am attempting to implement a Recurrent Neural Network (RCC) architecture of Long Short-Term Memory (LSTM) to identify rally patterns in professional Tennis matches - in an effort to implement Machine Learning solutions to Tennis players at a high level. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35u90OYYeoek",
        "colab_type": "text"
      },
      "source": [
        "### Algorithm Implementation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMmXng7ktKJP",
        "colab_type": "text"
      },
      "source": [
        "RCCs are Artificial Neural Networks designed for pattern recognition. They are adept identifying sequential data, using Backpropagation Through Time. This takes the current input value, and previously seen input values to give an output value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGgm5cIP_d8G",
        "colab_type": "text"
      },
      "source": [
        "LSTM based Neural Networks were posed as a solution to a common RCC issue - the Vanishing Gradient Problem. This was a Backpropagation problem, occurring when the Neural Network's loss function approached zero as more input layers were added - making model training difficult. LSTM's combat the Vanishing Gradient Problem by storing information outside the current Reccurent Network - aiding current sequence input analysis through remembering (or forgetting) similar imput patterns from previous network training iterations. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4RbQHv7BhXW",
        "colab_type": "text"
      },
      "source": [
        "For this project, the input value is going to be the first shot in a Tennis Rally (A serve). The output, will be the resultant five shots (based on the input). This number was chosen as it has been identified that a Server's advantage is lost around the 4th to 8th shot in a rally. Rally data will be formatted consistent with the Match Charting Project metadata standards.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvDuhJmibOll",
        "colab_type": "text"
      },
      "source": [
        "## Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHL25pckhjTY",
        "colab_type": "text"
      },
      "source": [
        "### Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMYYG44OvFdh",
        "colab_type": "text"
      },
      "source": [
        "The dataset contains point by point information from 169 professional tour level Tennis matches from 2001-2018, sourced from the Tennis Match Charting Project Github page. The dataset contains 57 different attributes and around 26,000 points, including: Player Names, Current Serving Player, Current Score, Rally Length, Point Winner, and, Rally Data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaHb-NY1J6wh",
        "colab_type": "text"
      },
      "source": [
        "#### Rally Data Explained\n",
        "\n",
        "Rally information is the most important attribute from the dataset, accounting for the LSTM Input and Output. An example rally is below;  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8htGUYcoLdEf",
        "colab_type": "text"
      },
      "source": [
        "#### Rally Example\n",
        "\n",
        "4+f18v3b3w@"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQrQyNMCMDFe",
        "colab_type": "text"
      },
      "source": [
        "#### Rally Example Explanation\n",
        "\n",
        "The above code represents a four-shot rally:\n",
        "- **4+**\n",
        "  - PlayerA hits a Serve out Wide on the Duece Court and runs towards net\n",
        "- **f18**\n",
        "  - PlayerB hits a moderately deep Forehand Return towards PlayerA's Forehand side (known as 'cross-court' in Tennis)\n",
        "- **v3**\n",
        "  - PlayerA hits a Forehand Volley from the net into PlayerB's Backhand court\n",
        "- **b3w@**\n",
        "  - PlayerB hits a Backhand towards PlayerA's backhand, missing the court wide and out\n",
        "  \n",
        "  \n",
        "Each dataset row contains similar sequences of metadata representing rallies. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0N9lLcEh25_",
        "colab_type": "text"
      },
      "source": [
        "### Dataset Preparation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sILHXlosyBKT",
        "colab_type": "text"
      },
      "source": [
        "The preparation of the dataset for RCC suitability can be broken into a Preprocessing phase and a Data Manipulation phase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bIoCOlaPWIr",
        "colab_type": "text"
      },
      "source": [
        "#### Preprocessing Phase\n",
        "This phase involved identifying relevant dataset input for LSTM modelling. Many steps here were formulated for solving Tennis related questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdkQaemQQA7e",
        "colab_type": "text"
      },
      "source": [
        "##### Eliminating Left-Handed Players from the Dataset\n",
        "Left handed-players were removed from the dataset for two reasons - the first, to standardize the represented player type. The second, for simplicity of data representation - due to Left-Handed players requiring different coded rally notation. Keeping these players would have led to sample size errors as well as confusing LSTM output notation.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Q_RLkOJQ_zm",
        "colab_type": "text"
      },
      "source": [
        "##### Eliminating Rallies where the First Serve Wasn't Legal\n",
        "If a player misses their First Serve of a point, they get a second attempt. All points where the player missed their First Serve were removed from the dataset. This was in an effort to focus on rally patterns resulting from a First Serve only."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ec1MZ9C5Q2CO",
        "colab_type": "text"
      },
      "source": [
        "##### Eliminating Rallies Under Two Shots in Length\n",
        "Rallies under two shots in length are usually ended by a good Serve, or an unnaturally good Return of Serve. These points are neither interesting for Tennis Knowledge, or, useful for LSTM Pattern Recognition - therefore, these points were removed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqbOnjH4ShpQ",
        "colab_type": "text"
      },
      "source": [
        "##### Splitting the Dataset into Return Focused Data by Court Position\n",
        "This was the largest piece of preprocessing, involving splitting the dataset into two sub-segments. This allowed for a more tailored LSTM approach, focusing entirely on the data from the Returning Player's point of view."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52HhfyBaTBNJ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "The major segment only used points won by the Returner, sub-segmented by points split by either of the starting court positions (Duece Side, or Advantage Side). Therefore, the final datasets were:\n",
        "- The Returner Won the Point, Returning from the Duece Side (2017 rows)\n",
        "- The Returner Won the Point, Returning from the Advantage Side (2685 rows)\n",
        "\n",
        " \n",
        "This step was important, due to the notation used for rally sequences. For example, the code \"6\" refers to hitting a serve through the centre of the court (known as the \"Tee\"). If a Server hits a Tee serve on the Duece Court, a right-handed Returner can only hit a Backhand (coded as \"b\"). However, if the Server hits a Tee serve (still coded \"6\") on the Advantage Court, the Returner can only hit a Forehand (coded as \"f\"). Therefore, segmenting the data by side prevented nonsensical LSTM output derived from the inability to differentiate which side of the court the point started.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5upzlO29Uer4",
        "colab_type": "text"
      },
      "source": [
        "#### Data Manipulation Phase\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ss7sgEYCxQeT",
        "colab_type": "text"
      },
      "source": [
        "The Data Manipulation Phase involved formatting the Rally data for Tokenization suitability, and usability in LSTM modelling. The previous rally data formatting was one large string, however, it needed to be sequential (structured similarly to a sentence). An Ad Hoc function was created to space rally data accordingly. After this structuring, a line break (\"\\n\") was added to each row for future formatting purposes. Using this function, the Rally Example from above became;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOr8UXN1Wf8H",
        "colab_type": "text"
      },
      "source": [
        "4+ f18 v3 b3w@\\n\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbqHQVG_bQe8",
        "colab_type": "text"
      },
      "source": [
        "## Methodology"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJq4trSJowNZ",
        "colab_type": "text"
      },
      "source": [
        "### Padded Rally Sequences\n",
        "To analyse rally patterns for Returning players, a Line-by-Line LSTM model was used. This model splits each rally sequentially shot-by-shot, observing how previous shots have a cause and effect relationship with future ones. This method also eliminates ambiguity where one shot can have multiple different output values.\n",
        "\n",
        "This format was used for Returners only, attempting to find a \"pseudo\" counter strategy (output as a rally sequence) to common Serve directions (input).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yADXVyT1c5h0",
        "colab_type": "text"
      },
      "source": [
        "### Padded Rally Sequences Code\n",
        "Below is the model code used. The input data is not included below, and can be found with the full code (provided above).\n",
        "\n",
        "The LSTM Model is broken into the following sections:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsPBhKdwd2h_",
        "colab_type": "text"
      },
      "source": [
        "#### Creating a Function to Generate Output Sequence\n",
        "The first step involves wrapping our LSTM model into a function for ease of use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo5mbSnSeSdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Create a Function For Generating a Sequence Given our Model\n",
        "### and Input Stimulus \n",
        "def generate_seq(model, tokenizer, max_length, first_serve, n_shots):\n",
        "\tin_text = first_serve\n",
        "\t# Below Generates a fixed number of words for Sequencing\n",
        "\tfor _ in range(n_shots):\n",
        "\t\t# \"Encoded\" creates sequences of words from the base stimulus\n",
        "\t\tencoded = tokenizer.texts_to_sequences([in_text])[0]\n",
        "\t\t# Below pads the created sequences so that they are equi-length\n",
        "\t\tencoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\t\t# This is a Keras module for predicting the likelihood of the next word\n",
        "    # given a group of words\n",
        "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
        "\t\t# This maps the output of a word from an integer value to the actual word.\n",
        "    # In our example this will give us a Rally Token\n",
        "\t\tout_word = ''\n",
        "\t\tfor word, index in tokenizer.word_index.items():\n",
        "\t\t\tif index == yhat:\n",
        "\t\t\t\tout_word = word\n",
        "\t\t\t\tbreak\n",
        "\t\t# This appends the predicted output to the input values\n",
        "    # (based on predictions from the model)\n",
        "\t\tin_text += ' ' + out_word\n",
        "\treturn in_text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-wB4W37efSa",
        "colab_type": "text"
      },
      "source": [
        "#### Sourcing and Tokenizing the Data\n",
        "Next, the data is Tokenized. This involves converting a string to a mapped integer. These integers can then be binarised so that the RCC can use them in the hidden layers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNv3RT6dfJKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Source and Tokenize Data\n",
        "# Here we are using our Returner Data on the Duece Side\n",
        "data = ds_r_w # Again, important to note that this dataset is not provided here\n",
        "# The Keras Tokenizer Module will tokenize our data to mapped integers\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([data])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQE_mPIOfYcZ",
        "colab_type": "text"
      },
      "source": [
        "#### Determining Vocabulary Size\n",
        "Next, we identify the vocabulary size and the number of unique words (or in this case, Rally Shots). This is an important step in the cleaning process for LSTM models. If running LSTM on a corpus, this step would involve Lower Casing all words for normalization. This is important as a more succinct allows for faster model training. In our use case however, the data is already Lower Cased, and the datasets are reasonably small."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M383Q6hhfc2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The next step is to determine the Vocabulary Size (number of unique words)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size: %d' % vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DRntNQofff5",
        "colab_type": "text"
      },
      "source": [
        "#### Padding Sequences\n",
        "Sequence Padding involves making sure each sequence is equal length. This is a feature that is necessary whilst using the Keras Library for RCC's. In the model, the sequences have been Padded to match the Maximum Length Sequence found in the dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSWEFDeCxXbE",
        "colab_type": "text"
      },
      "source": [
        "##### Sequence Padding Example\n",
        "Sequence Padding is used to make all Token Sequences an equal length. So, if the model has three Tokenized Sequences, represented as:\n",
        "\n",
        "[15, 8, 9, 1, 2]\n",
        "\n",
        "[15, 7, 9]\n",
        "\n",
        "[16, 8, 1, 23, 29, 5, 8]\n",
        "\n",
        "Post Padding, the Sequences would become:\n",
        "\n",
        "[0, 0, 15, 8, 9, 1, 2]\n",
        "\n",
        "[0, 0, 0, 0, 15, 7, 9]\n",
        "\n",
        "[16, 8, 1, 23, 29, 5, 8]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PnYtlvqghei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create and Pad Sequences\n",
        "# Below will create sequences of equal length for modelling\n",
        "sequences = list()\n",
        "for line in data.split('\\n'):# This is why we used \"\\n\" earlier, for splitting\n",
        "\tencoded = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(encoded)):\n",
        "\t\tsequence = encoded[:i+1]\n",
        "\t\tsequences.append(sequence)\n",
        "print('Total Sequences: %d' % len(sequences))\n",
        "\n",
        "# We then need to pad our sequences so that they are all the same length\n",
        "# This is a Keras Only Requirement, padding to our maximum length sequence. \n",
        "max_length = max([len(seq) for seq in sequences])\n",
        "sequences = pad_sequences(sequences, maxlen=max_length, padding='pre')\n",
        "print('Max Sequence Length: %d' % max_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KECZxq9dglpT",
        "colab_type": "text"
      },
      "source": [
        "#### Splitting Sequences into X and Y values\n",
        "\n",
        "Next, we need to split our generated Sequences into Input and Output elements (or X and Y values). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy2GKn1XhHBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This splits our sequences into X and Y values\n",
        "sequences = array(sequences)\n",
        "X, y = sequences[:,:-1],sequences[:,-1]\n",
        "y = to_categorical(y, num_classes=vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "du83-aJ6hLWD",
        "colab_type": "text"
      },
      "source": [
        "#### Creating the LSTM Model\n",
        "For the LSTM Neural Network, the Keras Sequential model is used. A Sequential Model is defined as a Linear Stack of layers. The Softmax Activation function was chosen over the Sigmoid Activation function due to the Multiclass nature of the Tennis Dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYR5LaiQhPpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here we Create our model. We are using a Sequential LSTM (using Softmax)\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 10, input_length=max_length-1))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j7VzPYghRRL",
        "colab_type": "text"
      },
      "source": [
        "#### Fitting the LSTM Model on Training Data\n",
        "The final section fits the Model using the Training Data. I used 625 Epochs (or total iterations through the entirety of the Training Data) however this may be unreasonable given Dataset sample sizes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQwD_f2CiXXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Next we must fit our model\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# Fit the Network given Training Data (625 Epochs takes a really long time!)\n",
        "model.fit(X, y, epochs=625, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kcZ59hy2LmV",
        "colab_type": "text"
      },
      "source": [
        "##### Loss Function, Optimizer, and Metrics used\n",
        "A Categorical Crossentropy Loss function was chosen over a Binary Crossentropy Loss Function due to the Multiclass nature of the Dataset. The Adam Optimization method (derived from \"Adaptive Movement Estimation\") was chosen instead of a more classical Stochastic Gradient Descent Optimization method, as Adam has been shown to outperform similar methods over comparable dataset iterations. Finally, using \"Accuracy\" for metrics will print the mean accuracy rate per Token Sequence prediction each iteration of the learning process. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlRU_DNUihn7",
        "colab_type": "text"
      },
      "source": [
        "#### Generating Output from the Model:\n",
        "To generate output, simply run the initially created function, inputting a rally shot code. For example, given the above code, and the following code:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRJeEvxLjBG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Output from model\n",
        "print(generate_seq(model, tokenizer, max_length-1, '6', 5))\n",
        "print(generate_seq(model, tokenizer, max_length-1, '5', 5))\n",
        "print(generate_seq(model, tokenizer, max_length-1, '4', 5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBRXUn8fi-Sr",
        "colab_type": "text"
      },
      "source": [
        "Output:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6 b28 f1 f1 f1 f1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "5 b28 f1 f1 f3 s3\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "4 f29 b2 f1 f1 f1\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE3jxKa8kRAT",
        "colab_type": "text"
      },
      "source": [
        "The above output was for points based on the Duece Side. If we ran the same code for the Advantage side, we would get:\n",
        "\n",
        "\n",
        "6 f28 f3 b3 b2 f3\n",
        "\n",
        "5 f28 f3 s2 f2d s3\n",
        "\n",
        "4 b28 f1 f2 f3 s3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lse2kvrFbSot",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LKvkKeBrP4z",
        "colab_type": "text"
      },
      "source": [
        "### Output from Model\n",
        "After running the model on both the Duece Side and Advantage Side Datasets, output for common rally sequences for Six and Ten shot rallies given an input value can be seen below for each side:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NpQR1HxKzcI",
        "colab_type": "text"
      },
      "source": [
        "#### Output for Common Shots in Rallies on the Duece Side \n",
        "\n",
        "**With Regular Serves (6 Shot Sequences)**\n",
        "\n",
        "6 b28 f3 b3 b3 s3\n",
        "\n",
        "5 b28 f 3 b3 i1\n",
        "\n",
        "4 f28 b2 b2 f2 f2\n",
        "\n",
        "**Rally Sequences (6 Shot Sequences)**\n",
        "\n",
        "b3 b3 b3 b2 f3 b3\n",
        "\n",
        "b2 f 1 f1 v3 m3\n",
        "\n",
        "b1 f2 f2 b2 f3 b3\n",
        "\n",
        "**With Regular Serves (10 Shot Sequences)**\n",
        "\n",
        "6 b28 f3 b3 b3 s3 b3 b2 f2 f2\n",
        "\n",
        "5 b28 f 3 b3 i1 f 3 m2 o3\n",
        "\n",
        "4 f28 b2 b2 f2 f2 f2 b2 f1w f1\n",
        "\n",
        "**Rally Sequences (10 Shot Sequences)**\n",
        "\n",
        "b3 b3 b3 b2 f3 b3 b2 b2 b3 b2\n",
        "\n",
        "b2 f 1 f1 v3 m3 p1 v3 s3w v1\n",
        "\n",
        "b1 f2 f2 b2 f3 b3 b2 f3 b3 b2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WZc1_YrL6F3",
        "colab_type": "text"
      },
      "source": [
        "#### Output for Common Shots in Rallies on the Advantage Side\n",
        "\n",
        "**With Regular Serves (6 Shot Sequences)**\n",
        "\n",
        "6 f28 f3 b3 b2 f1\n",
        "\n",
        "5 f28 f3 b3 b2d f3\n",
        "\n",
        "4 b38 s3 f 1 f1\n",
        "\n",
        "\n",
        "**Rally Sequences (6 Shot Sequences)**\n",
        "\n",
        "b3 b3 b3 b3 b3 b3\n",
        "\n",
        "b2 f3 b2u3 zn b3 z2\n",
        "\n",
        "b1 f1 f3 b3 b3 f3\n",
        "\n",
        "\n",
        "**With Regular Serves (10 Shot Sequences)**\n",
        "\n",
        "6 f28 f3 b3 b2 f1 f1 f1 f2 s3\n",
        "\n",
        "5 f28 f3 b3 b2d f3 s2n f 3 m\n",
        "\n",
        "4 b38 s3 f 1 f1 v3 b3 z2 l2\n",
        "\n",
        "\n",
        "**Rally Sequences (10 Shot Sequences)**\n",
        "\n",
        "b3 b3 b3 b3 b3 b3 b3 b3 b3 b3\n",
        "\n",
        "b2 f3 b2u3 zn b3 z2 f1 v3w b 1d\n",
        "\n",
        "b1 f1 f3 b3 b3 f3 b3 b3 b3 b1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt7TgvAaMtMg",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation of Output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmNtSGmedrg_",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "The output generated from the LSTM Model is fairly representative and realistic, echoing common Rally Sequences - for example, a lot of output rallies involved multiple cross-court shots, a regular pattern of play at high-level Tennis. \n",
        "\n",
        "Some model observations for Tennis players are:\n",
        "- _The Returner should aim for a deeper return of Serve_ - the output of the model always preferred deeper serve returns (regardless of Serve direction) over shorter ones. This suggests that if a Returner can hit a deeper Return of Serve, they are more likely to win the point.\n",
        "- _The Importance of Cross-Court Rally Sequences, Especially towards the Backhand side of the Court_ - the output of the model heavily featured shots played towards the Backhand corner of the court. This should be a major focus area for Tennis players. \n",
        "\n",
        "The model output also has some areas where it is somewhat nonsensical:\n",
        "- _Occasionally output will be split between shot and direction_ - for example \"f\" followed by \"1\" instead of \"f1\"\n",
        "- _Once rallies start going past a certain length they lose sensibility_ - this includes missed shots, or continuous looping rallies\n",
        "- _The model is unable to identify Net points_ - The model is unable to decipher how a player approaching the net forces the next shot that player hits to also be at the net. I believe this is a sample error, due to net play being uncommon at high-level play."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBGoYYze_OUG",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation of Model and Comparative Study\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xciPNYXdxN2",
        "colab_type": "text"
      },
      "source": [
        "The earlier Preprocessing steps allowed the model to differentiate Returner shot options based on previous shot and side of court, certainly validating the preprocessing methodology used. \n",
        "\n",
        "\n",
        "One negative of the model was the number of training epochs used - being too time consuming relative to marginal gain per epoch. The Accuracy Rate and Loss Rate by number of Epochs (for the Duece Side dataset) are shown below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF1MUFu-Y0Hj",
        "colab_type": "text"
      },
      "source": [
        "![Accuracy by Training Epochs](https://drive.google.com/uc?id=1MY9LhhFYiWs_JyqdWdToWzyMGxyqIW54)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_SLYJqWdMqL",
        "colab_type": "text"
      },
      "source": [
        "![Loss by Training Epochs](https://drive.google.com/uc?id=1n3wP_65uV-l9U--94g55IStjAm3fEQSS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDtPTUZMbUFF",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-qHtYljuGMC",
        "colab_type": "text"
      },
      "source": [
        "### Conclusion\n",
        "This Model doesn't give infallible Tennis Rally Sequence output for beating strong Serving players. The model is however, a good representation of the algorithmic usage of Long-Short Term Memory Recurrent Neural Networks, and would be better suited for tasks including Text Recognition, and (given enough data) Pattern Recognition in Price Based Markets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWPsIGIquMyS",
        "colab_type": "text"
      },
      "source": [
        "### Possible Improvements\n",
        "\n",
        "If I were to pursue the idea of using LSTM for Tennis Modelling further, a larger dataset would be necessary - due to the large number of unique Rally Sequences occuring in Tennis, and, also to the difficulty of modelling a sport containing an abundance of relevant input values. I would also try and normalize the rally length distribution more, allowing for a lower padding sequence length in model training.\n",
        "\n",
        "Given this, I recommend for Tennis Analysis, a different, more exploratory and visualisation based approach undertaken when attempting to use Analytics and Machine learning in this space. \n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9awFyrz9bs-m",
        "colab_type": "text"
      },
      "source": [
        "## Ethical\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbXL4X0rmzOr",
        "colab_type": "text"
      },
      "source": [
        "I believe that if we are to analyse Machine Learning Algorithms such as LSTM, they need to be observed under an umbrella of the \"Common-Good Approach\" of ethical decision making. This approach refers to any action undertaken being done with intent for the betterment of society as a whole.\n",
        "\n",
        "Pattern Recognition algorithms are already used efficiently in the medical space - featuring in areas indlucing: disease diagnosis, cancer detection, and even in hospital bed occupation forecasting. Methodologies such as these are far better at pattern recognition across sample spaces than humans are. There is a caveat however, that some human interaction is necessary when using machine learning to preserve human existence. The validation of the methodology and results of Machine Learning needs to be managed and monitored so that it is not misused, or misunderstood. Misconstruing information, or misusing input methodology leading to bad output data are problems that can have real human consequences. Whilst working symbiotically with Machine Learning, we need to ensure that we truly understand the methodology of using algorithmic solutions, and how the output can be properly used and managed if we wish to ethically pursue this area. \n",
        "\n",
        "A general rule of thumb, is that a computer shouldn't be able to make a decision that is inexplicable as a human - there needs to be a point of contact between the two.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-V_e-VePb8r2",
        "colab_type": "text"
      },
      "source": [
        "## Video Pitch"
      ]
    }
  ]
}